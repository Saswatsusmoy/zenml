{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quickstart-header"
   },
   "source": [
    "# ZenML Quickstart: From Agent-Only to Agent+Classifier\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/zenml-io/zenml/blob/main/examples/quickstart/quickstart.ipynb)\n",
    "\n",
    "**The modern AI development story in 5 minutes.**\n",
    "\n",
    "This quickstart demonstrates how ZenML unifies ML and Agent workflows, showing the natural progression from a generic agent to a specialized one powered by your own trained models.\n",
    "\n",
    "## üéØ The Story\n",
    "\n",
    "**Phase 1**: Deploy a support agent ‚Üí Generic responses  \n",
    "**Phase 2**: Train an intent classifier ‚Üí Tag as \"production\"  \n",
    "**Phase 3**: Same agent automatically upgrades ‚Üí Specialized responses  \n",
    "\n",
    "**The \"aha\" moment**: ZenML connects batch training and real-time serving with the same primitives. Train offline, promote artifacts to production, and agents automatically consume them online."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-section"
   },
   "source": [
    "## üõ†Ô∏è Setup\n",
    "\n",
    "First, let's install ZenML and required dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-dependencies"
   },
   "outputs": [],
   "source": [
    "# Install ZenML and dependencies\n",
    "!pip install \"zenml[server]\" scikit-learn requests -q\n",
    "\n",
    "# If running in Colab, we need to restart runtime after installation\n",
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    print(\n",
    "        \"‚ö†Ô∏è Please restart runtime after installation (Runtime ‚Üí Restart runtime)\"\n",
    "    )\n",
    "    print(\"Then continue with the next cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init-zenml"
   },
   "source": [
    "Initialize ZenML and set up the deployer stack:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zenml-init"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Initialize ZenML repository\n",
    "!zenml init\n",
    "\n",
    "# Set up deployer stack (required for serving)\n",
    "!zenml deployer register docker -f docker\n",
    "!zenml stack register docker-deployer -o default -a default -D docker --set\n",
    "\n",
    "print(\"‚úÖ ZenML setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download-files"
   },
   "source": [
    "Download the quickstart files if not already present:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "get-quickstart-files"
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from pathlib import Path\n",
    "\n",
    "# Base URL for quickstart files\n",
    "base_url = (\n",
    "    \"https://raw.githubusercontent.com/zenml-io/zenml/main/examples/quickstart\"\n",
    ")\n",
    "\n",
    "# Files to download\n",
    "files = {\n",
    "    \"run.py\": \"run.py\",\n",
    "    \"configs/agent.yaml\": \"configs/agent.yaml\",\n",
    "    \"pipelines/intent_training_pipeline.py\": \"pipelines/intent_training_pipeline.py\",\n",
    "    \"pipelines/agent_serving_pipeline.py\": \"pipelines/agent_serving_pipeline.py\",\n",
    "    \"steps/data.py\": \"steps/data.py\",\n",
    "    \"steps/train.py\": \"steps/train.py\",\n",
    "    \"steps/infer.py\": \"steps/infer.py\",\n",
    "    \"pipelines/__init__.py\": \"pipelines/__init__.py\",\n",
    "    \"steps/__init__.py\": \"steps/__init__.py\",\n",
    "}\n",
    "\n",
    "# Create directories and download files\n",
    "for file_path, local_path in files.items():\n",
    "    local_dir = Path(local_path).parent\n",
    "    local_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if not Path(local_path).exists():\n",
    "        try:\n",
    "            url = f\"{base_url}/{file_path}\"\n",
    "            urllib.request.urlretrieve(url, local_path)\n",
    "            print(f\"‚úÖ Downloaded {local_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to download {local_path}: {e}\")\n",
    "    else:\n",
    "        print(f\"üìÅ {local_path} already exists\")\n",
    "\n",
    "print(\"\\nüéâ All files ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "phase1-header"
   },
   "source": [
    "## üìã Phase 1: Deploy Agent-Only\n",
    "\n",
    "Let's deploy the agent without any classifier - it will use generic responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "deploy-agent"
   },
   "outputs": [],
   "source": [
    "# Deploy the agent serving pipeline\n",
    "!zenml pipeline deploy pipelines.agent_serving_pipeline.agent_serving_pipeline \\\n",
    "  -n support-agent -c configs/agent.yaml\n",
    "\n",
    "print(\"\\n‚úÖ Agent deployed! It's now running with generic responses only.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "test-phase1"
   },
   "source": [
    "Test the agent with a sample banking question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test-agent-generic"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "import requests\n",
    "\n",
    "# Wait a moment for deployment to be ready\n",
    "print(\"‚è≥ Waiting for agent to be ready...\")\n",
    "time.sleep(10)\n",
    "\n",
    "# Test the agent\n",
    "url = \"http://localhost:8000/invoke\"\n",
    "payload = {\"parameters\": {\"text\": \"my card is lost and i need a replacement\"}}\n",
    "\n",
    "try:\n",
    "    response = requests.post(\n",
    "        url, json=payload, headers={\"Content-Type\": \"application/json\"}\n",
    "    )\n",
    "    result = response.json()\n",
    "\n",
    "    print(\"ü§ñ Agent Response (Phase 1 - Generic):\")\n",
    "    print(json.dumps(result, indent=2))\n",
    "\n",
    "    # Parse the nested JSON response\n",
    "    if \"output\" in result:\n",
    "        agent_output = json.loads(result[\"output\"])\n",
    "        print(\n",
    "            f\"\\nüìä Intent Source: {agent_output.get('intent_source', 'unknown')}\"\n",
    "        )\n",
    "        print(f\"üéØ Detected Intent: {agent_output.get('intent', 'unknown')}\")\n",
    "        print(f\"üìà Confidence: {agent_output.get('confidence', 0):.2f}\")\n",
    "\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\n",
    "        \"‚ùå Could not connect to agent. Make sure Docker is running and the deployment succeeded.\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error testing agent: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "phase2-header"
   },
   "source": [
    "## üß† Phase 2: Train Intent Classifier\n",
    "\n",
    "Now let's train an intent classifier and automatically tag it as \"production\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train-classifier"
   },
   "outputs": [],
   "source": [
    "# Run the training pipeline\n",
    "!python run.py --train\n",
    "\n",
    "print(\"\\n‚úÖ Training complete! The classifier is now tagged as 'production'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "check-artifacts"
   },
   "source": [
    "Let's verify the artifact was created and tagged:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "verify-artifacts"
   },
   "outputs": [],
   "source": [
    "from zenml.client import Client\n",
    "\n",
    "# Check if our production artifact exists\n",
    "client = Client()\n",
    "try:\n",
    "    versions = client.list_artifact_versions(name=\"intent-classifier\")\n",
    "\n",
    "    print(\"üì¶ Intent Classifier Artifacts:\")\n",
    "    for version in versions:\n",
    "        tags = [tag.name for tag in version.tags] if version.tags else []\n",
    "        print(f\"  Version {version.version}: {tags}\")\n",
    "\n",
    "        if \"production\" in tags:\n",
    "            print(f\"  ‚úÖ Found production version: {version.version}\")\n",
    "            break\n",
    "    else:\n",
    "        print(\"  ‚ùå No production-tagged version found\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error checking artifacts: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "phase3-header"
   },
   "source": [
    "## üöÄ Phase 3: Agent Automatically Upgrades\n",
    "\n",
    "Update the same deployment - the agent will now load the production classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "update-deployment"
   },
   "outputs": [],
   "source": [
    "# Update the deployment with the -u flag\n",
    "!zenml pipeline deploy pipelines.agent_serving_pipeline.agent_serving_pipeline \\\n",
    "  -n support-agent -c configs/agent.yaml -u\n",
    "\n",
    "print(\"\\n‚úÖ Deployment updated! Agent will now use the production classifier.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "test-phase3"
   },
   "source": [
    "Test with the same request - now it should use the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test-agent-specialized"
   },
   "outputs": [],
   "source": [
    "# Wait for updated deployment to be ready\n",
    "print(\"‚è≥ Waiting for updated agent to be ready...\")\n",
    "time.sleep(15)\n",
    "\n",
    "# Test the upgraded agent\n",
    "try:\n",
    "    response = requests.post(\n",
    "        url, json=payload, headers={\"Content-Type\": \"application/json\"}\n",
    "    )\n",
    "    result = response.json()\n",
    "\n",
    "    print(\"ü§ñ Agent Response (Phase 3 - Specialized):\")\n",
    "    print(json.dumps(result, indent=2))\n",
    "\n",
    "    # Parse the nested JSON response\n",
    "    if \"output\" in result:\n",
    "        agent_output = json.loads(result[\"output\"])\n",
    "        print(\n",
    "            f\"\\nüìä Intent Source: {agent_output.get('intent_source', 'unknown')}\"\n",
    "        )\n",
    "        print(f\"üéØ Detected Intent: {agent_output.get('intent', 'unknown')}\")\n",
    "        print(f\"üìà Confidence: {agent_output.get('confidence', 0):.2f}\")\n",
    "\n",
    "        # Highlight the upgrade\n",
    "        if agent_output.get(\"intent_source\") == \"classifier\":\n",
    "            print(\"\\nüéâ SUCCESS! Agent is now using the trained classifier!\")\n",
    "        else:\n",
    "            print(\n",
    "                \"\\n‚ö†Ô∏è Agent is still using generic responses. Try again in a moment.\"\n",
    "            )\n",
    "\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\n",
    "        \"‚ùå Could not connect to agent. Make sure the deployment is running.\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error testing agent: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "comparison"
   },
   "source": [
    "## üîç The Magic Explained\n",
    "\n",
    "Let's look at how the automatic upgrade works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "show-magic"
   },
   "outputs": [],
   "source": [
    "# Show the key code that makes this work\n",
    "print(\"ü™Ñ The Automatic Upgrade Logic:\")\n",
    "print(\"\"\"\n",
    "# At deployment startup (on_init_hook)\n",
    "def _load_production_classifier_if_any():\n",
    "    versions = client.list_artifact_versions(name=\"intent-classifier\")\n",
    "\n",
    "    for version in versions:\n",
    "        if \"production\" in [tag.name for tag in version.tags]:\n",
    "            global _router\n",
    "            _router = version.load()  # üéØ Agent upgraded!\n",
    "            break\n",
    "\n",
    "# The Decision Logic:\n",
    "if _router is not None:\n",
    "    # ‚úÖ Use classifier for specific responses\n",
    "    intent_source = \"classifier\"\n",
    "else:\n",
    "    # ‚ùå Use generic LLM responses  \n",
    "    intent_source = \"llm\"\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nüéØ Key Points:\")\n",
    "print(\"1. üöÄ Deploy once ‚Üí Agent works immediately with generic responses\")\n",
    "print(\"2. üß† Train model ‚Üí Automatically tagged as 'production'\")\n",
    "print(\"3. üîÑ Update deployment ‚Üí Agent finds and loads the production model\")\n",
    "print(\"4. ‚ú® Same endpoint, better responses ‚Üí No code changes needed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "test-different-intents"
   },
   "source": [
    "## üß™ Test Different Banking Intents\n",
    "\n",
    "Let's test the classifier with different banking questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test-intents"
   },
   "outputs": [],
   "source": [
    "# Test different banking intents\n",
    "test_cases = [\n",
    "    \"what is my current balance\",\n",
    "    \"i need to make a payment\",\n",
    "    \"i want to dispute a charge\",\n",
    "    \"can you increase my credit limit\",\n",
    "    \"hello can you help me\",\n",
    "]\n",
    "\n",
    "print(\"üß™ Testing Different Banking Intents:\\n\")\n",
    "\n",
    "for i, test_text in enumerate(test_cases, 1):\n",
    "    print(f\"Test {i}: '{test_text}'\")\n",
    "\n",
    "    payload = {\"parameters\": {\"text\": test_text}}\n",
    "\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            url, json=payload, headers={\"Content-Type\": \"application/json\"}\n",
    "        )\n",
    "        result = response.json()\n",
    "\n",
    "        if \"output\" in result:\n",
    "            agent_output = json.loads(result[\"output\"])\n",
    "            intent = agent_output.get(\"intent\", \"unknown\")\n",
    "            confidence = agent_output.get(\"confidence\", 0)\n",
    "            source = agent_output.get(\"intent_source\", \"unknown\")\n",
    "\n",
    "            print(\n",
    "                f\"  ‚Üí Intent: {intent} (confidence: {confidence:.2f}, source: {source})\"\n",
    "            )\n",
    "        else:\n",
    "            print(\"  ‚Üí Error: No output in response\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚Üí Error: {e}\")\n",
    "\n",
    "    print()\n",
    "    time.sleep(1)  # Brief pause between requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup"
   },
   "source": [
    "## üßπ Cleanup\n",
    "\n",
    "Stop the deployment when you're done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "stop-deployment"
   },
   "outputs": [],
   "source": [
    "# Stop the deployment\n",
    "try:\n",
    "    !zenml deployment delete support-agent\n",
    "    print(\"‚úÖ Deployment stopped and cleaned up.\")\n",
    "except:\n",
    "    print(\"‚ÑπÔ∏è Deployment may have already been stopped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "conclusion"
   },
   "source": [
    "## üéØ What You Just Learned\n",
    "\n",
    "Congratulations! You've experienced ZenML's unified ML and Agent workflow:\n",
    "\n",
    "### üîÑ **The Progression**\n",
    "1. **Generic Agent** ‚Üí Deployed instantly, works with basic responses\n",
    "2. **Trained Classifier** ‚Üí Added specialized intelligence with production tagging\n",
    "3. **Automatic Upgrade** ‚Üí Same endpoint, enhanced capabilities\n",
    "\n",
    "### üèóÔ∏è **ZenML Features Demonstrated**\n",
    "- ‚úÖ **Unified Workflows**: Same primitives for batch training and real-time serving\n",
    "- ‚úÖ **Production Tagging**: Automatic artifact promotion with `add_tags()`\n",
    "- ‚úÖ **Warm Container Serving**: Models load once at startup for fast responses\n",
    "- ‚úÖ **Artifact Lineage**: Full tracking from training to deployment\n",
    "- ‚úÖ **Stack Portability**: Deploy anywhere with consistent APIs\n",
    "\n",
    "### üåü **Key Takeaway**\n",
    "*One framework for ML and Agents. Train offline, promote artifacts into production, and serve online with the same developer experience.*\n",
    "\n",
    "---\n",
    "\n",
    "### üöÄ **Next Steps**\n",
    "- üìñ [Full ZenML Documentation](https://docs.zenml.io/)\n",
    "- üí¨ [Join our Community](https://zenml.io/slack)\n",
    "- üè¢ [ZenML Pro](https://zenml.io/pro) for teams\n",
    "- üåê [More Examples](https://github.com/zenml-io/zenml/tree/main/examples)\n",
    "\n",
    "**Ready to build your own AI workflows?** ZenML provides the infrastructure to make them reliable, reproducible, and production-ready."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}